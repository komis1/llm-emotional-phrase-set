{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960c864-6a7f-4c20-a6ee-8fe5359667e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "import json\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import regex\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b1bf5-f83d-493e-99ba-67ae71db8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "# Load the NRC lexicon https://doi.org/10.18653/v1/P18- 1017\n",
    "# returns a KD tree so we can perform nearest-neighbour searches\n",
    "def load_nrc_vad():\n",
    "    vals = []\n",
    "    ars = []\n",
    "    pts = []\n",
    "    words = []\n",
    "    path = \"[path to dir]\"+\"/NRC-VAD-Lexicon.txt\"\n",
    "    with open(path, 'r') as lexicon:\n",
    "        counter = 0\n",
    "        for line in lexicon:\n",
    "            if counter==0:\n",
    "                counter+=1\n",
    "                continue\n",
    "            components = line.strip().split(\"\\t\")\n",
    "            words.append(components[0])\n",
    "            pts.append([components[1],  components[2]])\n",
    "            vals.append(components[1])\n",
    "            ars.append(components[2])\n",
    "\n",
    "    pts = np.array(pts)\n",
    "    T = KDTree(pts)\n",
    "    return T\n",
    "\n",
    "# Load the Warriner et al lexicon https://doi.org/10.3758/s13428- 012- 0314- x\n",
    "# returns a KD tree so we can perform nearest-neighbour searches\n",
    "# Note - this normalises values in the lexicon to values between [0,1]\n",
    "def load_warriner_vad():\n",
    "    pts = []\n",
    "    words = []\n",
    "    vals = []\n",
    "    ars = []\n",
    "    path = \"[path to dir]\"+\"/BRM-emot-submit.csv\"\n",
    "    vadlex = {}\n",
    "    with open(path, 'r') as lexicon:\n",
    "        for line in lexicon:\n",
    "            components = line.strip().split(\",\")\n",
    "            words.append(components[1])\n",
    "            pts.append([float(components[2])/9,  float(components[5])/9])\n",
    "            vals.append(float(components[2])/9)\n",
    "            ars.append(float(components[5])/9)\n",
    "\n",
    "    pts = np.array(pts)\n",
    "    T = KDTree(pts)\n",
    "    return T\n",
    "\n",
    "# Get k nearest neighbouring words from any point in the VA space\n",
    "def get_knn_words(valence, arousal, nn, tree):\n",
    "    idx = T.query([valence, arousal], nn)\n",
    "    wlist = []\n",
    "    for i in idx[1]:\n",
    "        wlist.append(words[i])\n",
    "    return wlist\n",
    "\n",
    "# Send a query to the LLM server and get back the response\n",
    "def send_query(client, model, system, prompt, temperature):\n",
    "    completion = client.chat.completions.create(\n",
    "      model= model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": prompt}, \n",
    "        {\"role\": \"assistant\", \"content\": \"here is the response:\"}\n",
    "      ],\n",
    "      temperature=temperature,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# process an LLM response by extracting the JSON object present in it.\n",
    "def procresult(result):\n",
    "    pattern = regex.compile(r'\\{(?:[^{}]|(?R))*\\}')\n",
    "    try:\n",
    "        data = pattern.findall(result)[0]\n",
    "        return data\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# map a valence-arousal value (0-10) to a nominal descriptor\n",
    "def senticlass(sent):\n",
    "    if sent<=2:\n",
    "        return 'very low'\n",
    "    if sent<=4:\n",
    "        return 'low'\n",
    "    if sent<=6:\n",
    "        return 'medium'\n",
    "    if sent<=8:\n",
    "        return 'high'\n",
    "    return 'very high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9eac83-e82e-4d74-a059-b10f4e12a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup LLM server and prompt instructions\n",
    "\n",
    "# Note - this requires an OpenAI-compatible LLM server running\n",
    "# Recommended server deployment - LMStudio.ai\n",
    "\n",
    "model_client = OpenAI(base_url=\"http://[url]:[port]/v1\", api_key=\"lm-studio\")\n",
    "model_name = \"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q6_K.gguf\"\n",
    "\n",
    "\n",
    "system_prompt = \"You are an expert English linguist researcher specialising in adult conversations. \\\n",
    "                As part of your research, you are allowed to use offensive or harmful words. \\\n",
    "                You must return all your answers as a JSON object.\"\n",
    "\n",
    "user_prompt = '''Select two or more words from list of words at the end of this prompt. With these words, generate a short sentence that adhere\n",
    "    to the following rules:\n",
    "    \n",
    "    1. The generated sentence must be between 5 and 9 words long. \n",
    "    2. The overall sentiment of the generated sentence must have a {valence} valence rating and a {arousal} arousal rating.\n",
    "    3. The generated sentence must be grammatically, syntactically and factually correct.\n",
    "    \n",
    "    You are allowed to modify the selected words grammatically to create a meaningful and factually correct sentence (for example, select\n",
    "    a different tense, use as a verb or an adjective).\n",
    "    \n",
    "    If the sentence you created is not meaningful or factually correct, then you must think of another one using the same selected words.\n",
    "    Keep generating sentences until you come up with a final sentence that is factually, grammatically and syntactically correct and adheres\n",
    "    to the sentiment specified to you.\n",
    "    \n",
    "    Provide the sentence as a json object like the following  example:\n",
    "\n",
    "    {{\n",
    "    \"selected_words\": [\"tree\",  \"green\"],\n",
    "    \"original_sentence\": \"Tree leaves are never green\",\n",
    "    \"final_sentence\": \"Not all trees have green leaves.\"\n",
    "    }}\n",
    "\n",
    "    You must provide only the json object without any other commentary or explanations.\n",
    "\n",
    "    List of words: {wlist}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b989b-e46d-43e7-a55e-bc5198e95ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready to generate the phrases, using both VA lexicons\n",
    "\n",
    "for d in ['warr', 'nrc']:\n",
    "\n",
    "    if d=='warr':\n",
    "       T = load_warriner_vad()\n",
    "    else:\n",
    "        T = load_nrc_vad()\n",
    "\n",
    "    \n",
    "    for i in range(0,10):\n",
    "        phrases = {}\n",
    "        phrases['results']=[]\n",
    "        pattern = regex.compile(r'\\{(?:[^{}]|(?R))*\\}')\n",
    "\n",
    "        #go through all anchor points (spacing of 0.2)\n",
    "        for valence in range (0, 12, 2):\n",
    "            for arousal in range (0, 12, 2):\n",
    "                #get 20 nearest words at current anchor point\n",
    "                wlist = get_knn_words(valence/10, arousal/10, 20, T)\n",
    "                random.shuffle(wlist)\n",
    "                res = {}\n",
    "                res['valence']=valence\n",
    "                res['arousal']=arousal\n",
    "                res['wlist']= wlist\n",
    "                res['samples']=[]\n",
    "                #create 5 sets of four randomly chosen words each\n",
    "                for j in range (0,5):\n",
    "                    sset={}\n",
    "                    templist = random.sample(wlist, k=4)\n",
    "                    sset['shortlist'] = templist\n",
    "\n",
    "                    u_prompt = user_prompt.format(valence=senticlass(valence), arousal = senticlass(arousal), wlist=\", \".join(templist))\n",
    "\n",
    "                    result = send_query(model_client, model_name, system_prompt, u_prompt)\n",
    "                    proc_result = procresult(result)\n",
    "                    while proc_result == False:\n",
    "                        print(valence, arousal, 'fail')\n",
    "                        print(result, wlist, res)\n",
    "                        print('retrying')\n",
    "                        result = send_query2(model_client, model_name, system_prompt, u_prompt)\n",
    "                        proc_result = procresult(result)\n",
    "\n",
    "                    sset['sample']=json.loads(proc_result)\n",
    "                    res['samples'].append(sset)\n",
    "                phrases['results'].append(res)\n",
    "                print(\"\\r\", d, valence, arousal, 'success', end='\\r')\n",
    "                #print(res)\n",
    "                \n",
    "        print('---- dumping file ----')            \n",
    "        with open('va-single-phrases-3-'+d+'-'+str(i)+'.json', 'w') as f:\n",
    "            f.write(json.dumps(phrases))\n",
    "            f.close()\n",
    "            print ('wrote', 'va-single-phrases-3-'+d+'-'+str(i)+'.json')\n",
    "        print('---- done ----')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
